{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/kassupto007/artificial_intelligence_assignment_3/blob/main/assignment3.ipynb#scrollTo=96JJb5LL3gPe\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports section\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Temperature °C  Mols KCL     Size nm^3\n",
      "0              469       647  6.244743e+05\n",
      "1              403       694  5.779610e+05\n",
      "2              302       975  6.196847e+05\n",
      "3              779       916  1.460449e+06\n",
      "4              901        18  4.325726e+04\n",
      "5              545       637  7.124634e+05\n",
      "6              660       519  7.006960e+05\n",
      "7              143       869  2.718260e+05\n",
      "8               89       461  8.919803e+04\n",
      "9              294       776  4.770210e+05\n",
      "10             991       117  2.441771e+05\n",
      "11             307       781  5.006455e+05\n",
      "12             206        70  3.145200e+04\n",
      "13             437       599  5.390215e+05\n",
      "14             566        75  9.185271e+04\n",
      "\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Temperature °C  1000 non-null   int64  \n",
      " 1   Mols KCL        1000 non-null   int64  \n",
      " 2   Size nm^3       1000 non-null   float64\n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 23.6 KB\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "       Temperature °C     Mols KCL     Size nm^3\n",
      "count     1000.000000  1000.000000  1.000000e+03\n",
      "mean       500.500000   471.530000  5.086111e+05\n",
      "std        288.819436   288.482872  4.474838e+05\n",
      "min          1.000000     1.000000  1.611429e+01\n",
      "25%        250.750000   226.750000  1.298267e+05\n",
      "50%        500.500000   459.500000  3.827182e+05\n",
      "75%        750.250000   710.250000  7.603211e+05\n",
      "max       1000.000000  1000.000000  1.972127e+06\n"
     ]
    }
   ],
   "source": [
    "# Using pandas load the dataset (load remotely, not locally)\n",
    "slime = pd.read_csv(\"https://raw.githubusercontent.com/profmcnich/example_notebook/main/science_data_large.csv\")\n",
    "\n",
    "# Output the first 15 rows of the data\n",
    "print(slime.head(15), end=\"\\n\\n\\n\\n\")\n",
    "\n",
    "# Display a summary of the table information (number of datapoints, etc.)\n",
    "print(slime.info(), end=\"\\n\\n\\n\\n\")\n",
    "print(slime.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the pandas dataset and split it into our features (X) and label (y)\n",
    "features_x = slime.iloc[0:, 0:2]\n",
    "label_y = slime.iloc[0:, 2]\n",
    "\n",
    "\n",
    "# Use sklearn to split the features and labels into a training/test set. (90% train, 10% test)\n",
    "x_train, x_test, y_train, y_test = train_test_split(features_x, label_y, train_size = 0.9, test_size = 0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Perform a Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  [ 235911.1927226   830451.79732027  969401.72391381 1326783.358643\n",
      "  884987.0194726    45565.47278428  258437.07158696  343780.52496405\n",
      "  564054.54417373  458809.58094581  661981.4155175   271858.83784998\n",
      "  903037.34361731   69482.60670887  379028.57233118  759890.29754812\n",
      "   82272.51567904  456112.80060588  455253.66048099 1209189.73365483\n",
      "  -48211.69480861 -385772.63855955 1181406.24213132  726518.89857463\n",
      "  336685.73917576  154234.6122294   607815.96342049  802405.75147334\n",
      "  965869.86487882  126083.68608006  374198.19430497  207569.65649033\n",
      "  549129.16917369  690734.99958497  448521.17137364  923060.78891187\n",
      "  681538.61800052  485528.84259863  574708.98711403  888519.34559349\n",
      "  427260.4083527   122581.02641978  891216.12593342  297249.44696507\n",
      "  635710.40736308  955479.37751965  547489.61241598  535403.97206505\n",
      "  428268.10781756  827755.01698035  393616.179166   1263489.26542894\n",
      " 1112311.21126119  191472.83588771 -208148.62003809 1000880.35352413\n",
      "  570676.080862    569784.938847    105630.20363716  486163.50240687\n",
      "  947784.73632861  862567.88925424  243211.0682567   718247.99632477\n",
      " 1185300.86493315  385792.59624273  928993.00372966  687066.72544338\n",
      "  822952.43707116  333756.53805891  959072.90490536  208335.59346029\n",
      "  555989.19875557  747398.21439279   59020.1751092   887679.12895354\n",
      "   12085.4568212   -22026.41643474  811932.89493453  436988.9048725\n",
      "  269933.5995108   439394.39860018 1011906.43486335  709759.15296085\n",
      "  188216.14249542  340584.09866479  827755.48406625  328425.57990157\n",
      "  490796.73114755  651063.01699607 1086728.12371956 1213150.69566636\n",
      "  788705.08288042  520268.83646022 1065876.60601842  703960.08364837\n",
      "  852035.38175768  889187.40854954  936685.3094912  -296694.10474525]\n"
     ]
    }
   ],
   "source": [
    "# Use sklearn to train a model on the training set\n",
    "reg = LinearRegression()\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "# Create a sample datapoint and predict the output of that sample with the trained model\n",
    "predictions = reg.predict(x_test)\n",
    "print(\"Predictions: \", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 value:  0.8606369652963943\n"
     ]
    }
   ],
   "source": [
    "# Report on the score for that model, in your own words (markdown, not code) explain what the score means\n",
    "print(\"R^2 value: \",reg.score(features_x, label_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What does the score mean? \n",
    "- R-squared is a goodness-of-fit measure for linear regression models. It is the proportion of sample variance explained by predictors in the model.\n",
    "- This model has a 86% accuracy in predicting the size of slime based on temperature and mol variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temp coef:  866.1464133719222    Mol Coef: 1032.6950664857966\n",
      "Intercept:  -409391.47958340833\n"
     ]
    }
   ],
   "source": [
    "# Extract the coefficents and intercept from the model and write an equation for your h(x) using LaTeX\n",
    "temp_coef = reg.coef_[0]\n",
    "mols_coef = reg.coef_[1]\n",
    "print(\"Temp coef: \", temp_coef, \"   Mol Coef:\" ,mols_coef)\n",
    "\n",
    "intercept = reg.intercept_\n",
    "print(\"Intercept: \", intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equation: $h(x) = -409391 + 866.15 temp + 1032.7 mol$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4. Use Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81123596, 0.86440978, 0.87808742, 0.86561069, 0.87495621,\n",
       "       0.84484397, 0.87941022, 0.86349411, 0.78353682, 0.88686516])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the cross_val_score function to repeat your experiment across many shuffles of the data\n",
    "scores = cross_val_score(reg, features_x, label_y, cv = 10)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86 accuracy with a standard deviation of 0.03\n"
     ]
    }
   ],
   "source": [
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report on their finding and their significance\n",
    "- Cross-Validation gives a more accurate score value because it guarantees that the score of our model does not depend on the way we picked the train and test set. The data set is divided into k number of subsets and the holdout method is repeated k number of times. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5. Using Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the PolynomialFeatures library perform another regression on an augmented dataset of degree 2\n",
    "polynomial = PolynomialFeatures(2)\n",
    "x_test = polynomial.fit_transform(x_test)\n",
    "x_train = polynomial.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  [1.17762314e+05 8.68729257e+05 1.08489300e+06 1.71603946e+06\n",
      " 9.53685000e+05 1.15057114e+05 2.22299400e+05 2.85719400e+05\n",
      " 2.87802714e+05 3.58129714e+05 2.43109457e+05 2.56621829e+05\n",
      " 8.23168314e+05 1.28610714e+05 3.55214714e+05 5.49207314e+05\n",
      " 7.11794571e+04 4.10720600e+05 2.17334314e+05 1.48665911e+06\n",
      " 7.61464000e+04 3.30257161e+02 1.44061911e+06 6.87856114e+05\n",
      " 3.04432457e+05 1.23172829e+05 3.30255457e+05 7.97577257e+05\n",
      " 1.07736803e+06 1.50313257e+05 3.50800114e+05 1.16391429e+05\n",
      " 3.60092314e+05 6.22649829e+05 3.89294314e+05 9.72528114e+05\n",
      " 4.92891314e+05 4.52268000e+05 5.54434600e+05 9.38430829e+05\n",
      " 2.24846314e+05 8.28351143e+04 9.65613829e+05 1.14028114e+05\n",
      " 4.08676457e+05 1.01254603e+06 4.80946400e+05 3.60768257e+05\n",
      " 3.19070314e+05 8.73038314e+05 3.05002257e+05 1.59435511e+06\n",
      " 1.24219443e+06 1.48395457e+05 1.36031143e+04 1.10432926e+06\n",
      " 5.25291429e+05 2.44177114e+05 1.18924114e+05 4.55983857e+05\n",
      " 9.71624114e+05 9.13729029e+05 2.45060457e+05 4.03842857e+05\n",
      " 1.40512903e+06 3.34372457e+05 1.02252331e+06 3.37170857e+05\n",
      " 6.80136829e+05 3.11877257e+05 1.04920946e+06 1.30851000e+05\n",
      " 4.94674314e+05 5.56986600e+05 6.51534571e+04 7.32261029e+05\n",
      " 1.02109714e+05 7.88616000e+04 8.23033029e+05 3.03944714e+05\n",
      " 2.77241143e+04 3.42182029e+05 1.10411426e+06 7.12977114e+05\n",
      " 1.50487143e+04 3.19512429e+05 8.68479400e+05 3.13061829e+05\n",
      " 3.77713029e+05 6.39442429e+05 1.24874203e+06 1.46083211e+06\n",
      " 4.99694829e+05 1.89236829e+05 1.23976740e+06 6.30519857e+05\n",
      " 7.67623429e+05 8.68430829e+05 9.73751114e+05 4.78631430e+03]\n"
     ]
    }
   ],
   "source": [
    "# Use sklearn to train a model on the training set\n",
    "bayesian = BayesianRidge()\n",
    "bayesian.fit(x_train, y_train)\n",
    "\n",
    "# Create a sample datapoint and predict the output of that sample with the trained model\n",
    "bayesian_predictions = bayesian.predict(x_test)\n",
    "print(\"Predictions: \", bayesian_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Report on the score for that model\n",
    "print(\"Score: \",bayesian.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficent:  [ 0.00000000e+00  1.20000000e+01 -1.24733879e-07  1.37881928e-11\n",
      "  2.00000000e+00  2.85714287e-02]\n",
      "Intercept:  2.016982762143016e-05\n"
     ]
    }
   ],
   "source": [
    "# Extract the coefficents and intercept from the model and write an equation for your h(x) using LaTeX\n",
    "coefficent = bayesian.coef_\n",
    "print(\"coefficent: \", coefficent)\n",
    "\n",
    "intercept = bayesian.intercept_\n",
    "print(\"Intercept: \", intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equation: $h(x) = 0.0000 + 12.000a - 0.0000b - 0.0000a^2 + 2.0000ab + 0.02857b^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report\n",
    "- I used Bayesian Ridge Regression for part 5. This model has a 100% accuracy in predicting the size of slime based on temperature and mol variables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
